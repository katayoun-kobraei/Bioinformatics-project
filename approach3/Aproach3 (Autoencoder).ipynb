{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.decomposition import PCA\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_drug = pd.read_pickle('/kaggle/input/datasetname/df.pkl')\n",
    "conn = sqlite3.connect(\"/kaggle/input/datasetname/event.db\")\n",
    "extraction = pd.read_sql('select * from extraction;', conn)\n",
    "extraction.drop(columns=['index'], inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_drug.drop(columns=['index', 'id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def f_extractor(df, f_list):\n",
    "    for feature in f_list:\n",
    "        unique = set('|'.join(df[feature].values.tolist()).split('|'))\n",
    "\n",
    "        for side in unique:\n",
    "            df[side] = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            for side in row[feature].split('|'):\n",
    "                df.at[index, side] = 1\n",
    "    df.drop(columns=f_list, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f_list = ['side', 'target', 'enzyme', 'pathway', 'smile']\n",
    "\n",
    "f_extractor(df_drug, f_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_autoencoder(autoencoder, train_loader, test_loader, num_epochs):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train the autoencoder\n",
    "        running_train_loss = 0.0\n",
    "        num_train_correct = 0\n",
    "        num_train_total = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            inputs = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            num_train_correct += (predicted == inputs).sum().item()\n",
    "            num_train_total += inputs.numel()\n",
    "\n",
    "        # test the autoencoder\n",
    "        running_test_loss = 0.0\n",
    "        num_test_correct = 0\n",
    "        num_test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data.to(device)\n",
    "                inputs = data\n",
    "                outputs = autoencoder(data)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                running_test_loss += loss.item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                num_test_correct += (predicted == inputs).sum().item()\n",
    "                num_test_total += inputs.numel()\n",
    "\n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_acc = num_train_correct / num_train_total\n",
    "        test_loss = running_test_loss / len(test_loader)\n",
    "        test_acc = num_test_correct / num_test_total\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.4f}'.format(epoch+1, num_epochs, train_loss, train_acc, test_loss, test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DrugDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = torch.tensor(df.values.astype('float32'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "input_dim = 12_829\n",
    "encoding_dim = 512\n",
    "num_epochs = 1_000\n",
    "\n",
    "autoencoder = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_drug, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = DrugDataset(df_train.drop(columns=['name']))\n",
    "test_dataset = DrugDataset(df_test.drop(columns=['name']))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "train_autoencoder(autoencoder, train_loader, test_loader, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = autoencoder.encoder\n",
    "for param in encoder:\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extraction['side'] = extraction['mechanism'] + extraction['action']\n",
    "extraction.drop(columns=['mechanism', 'action'], inplace=True)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "extraction['side'] = le.fit_transform(extraction['side'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DDIDataset(Dataset):\n",
    "    def __init__(self, df, extraction, encoder):\n",
    "        self.extraction = extraction\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        drugA = torch.tensor(self.df[self.df['name'] == self.extraction.loc[0]['drugA']].drop(columns=['name']).values.astype('float32')).to(device)\n",
    "        drugB = torch.tensor(self.df[self.df['name'] == self.extraction.loc[0]['drugB']].drop(columns=['name']).values.astype('float32')).to(device)\n",
    "        return torch.cat([encoder(drugA),encoder(drugB)]), self.extraction.loc[idx]['side']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ddset = DDIDataset(df_drug, extraction, encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train2(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the running loss\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Compute the average training loss and accuracy for this epoch\n",
    "        train_loss = running_train_loss / len(train_dataset)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        running_test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Forward pass\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Compute the accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "                # Update the running loss\n",
    "                running_test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Compute the average testing loss and accuracy for this epoch\n",
    "        test_loss = running_test_loss / len(test_dataset)\n",
    "        test_acc = correct_test / total_test\n",
    "\n",
    "        # Print the loss and accuracy for this epoch\n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2 * 512, 256)\n",
    "        self.fc2 = nn.Linear(256, 65)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2 * 512) # Flatten the input tensor\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.softmax(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ddset))\n",
    "test_size = len(ddset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(ddset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = ClassificationModel()\n",
    "model.to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "train2(model, train_loader, test_loader, criterion, optimizer, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}